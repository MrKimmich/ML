{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of NumPy Coding Assignment 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "06f22e03-17d2-45c2-95a4-b617e45a6339"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i9LXloxlIWr"
      },
      "source": [
        "### 1. Macro-averaged F1-score\n",
        "\n",
        "Implement the `macro_averaged_f1_score()` function which computes the Macro-averaged F1 score for a multi-class classification problem.\n",
        "\n",
        "\n",
        "$$\\text{Precision (P) = }\\frac{TP}{TP+FP}$$\n",
        "<br>\n",
        "$$\\text{Recall (R) = }\\frac{TP}{TP+FN}$$\n",
        "<br>\n",
        "$$\\text{F1-score = }\\frac{2PR}{P+R}$$\n",
        "<br>\n",
        "$$\\text{Macro-averaged F1-score = }\\frac{\\text{Sum of F1-scores of all classes }}{\\text{Number of classes}}$$\n",
        "\n",
        "\n",
        "**Arguments**:\n",
        "* **`actual_Y`** :  Actual labels of instances.\n",
        "    * A 1D numpy array of chars\n",
        "    * Array shape: (number of instances, )\n",
        "* **`predicted_Y`**: Predicted labels of instances.\n",
        "    * A 1D numpy array of chars\n",
        "    * Array shape: (number of instances, )\n",
        "    * Assume that `predicted_Y` does not have labels which are not in `actual_Y`\n",
        "\n",
        "\n",
        "**Returns**:\n",
        "Macro-averaged F1-score (A float value)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03aeced1-552d-46f5-910b-9f10ff01836f"
      },
      "source": [
        "def macro_averaged_f1_score(actual_Y, predicted_Y):\n",
        "  #ADD YOUR CODE HERE\n",
        "  def recall(label, confusion_matrix):\n",
        "    row = confusion_matrix[label, :]\n",
        "    return confusion_matrix[label, label] / row.sum()\n",
        "  \n",
        "  def precision(label, confusion_matrix):\n",
        "      col = confusion_matrix[:, label]\n",
        "      return confusion_matrix[label, label] / col.sum()\n",
        "    \n",
        "\n",
        "  k = 0\n",
        "  if len(np.unique(actual_Y))>len(np.unique(predicted_Y)):\n",
        "    k = len(np.unique(actual_Y))\n",
        "  else:\n",
        "    k = len(np.unique(predicted_Y))\n",
        "  cm = np.zeros((k, k), int)\n",
        "  for i in range(len(actual_Y)):\n",
        "    cm[ord(actual_Y[i])-65][ord(predicted_Y[i])-65] += 1\n",
        "  cm = np.transpose(cm)\n",
        "  #print(cm)\n",
        "  rows, columns = cm.shape\n",
        "  sum_of_f1 = 0\n",
        "  for label in range(columns):\n",
        "      r = recall(label, cm)\n",
        "      p = precision(label, cm)\n",
        "      #print(r, p)\n",
        "      temp = float((2*r*p)/(r+p))\n",
        "      if np.isnan(temp):\n",
        "        continue\n",
        "      else:\n",
        "        sum_of_f1 += temp\n",
        "      #print(\"sum \", sum_of_f1)\n",
        "  return sum_of_f1 / columns \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15FKlXP0n8MK",
        "outputId": "c8781de8-e719-4df1-e57c-df9f2f847091",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "actual_Y = np.array([\"A\",\"B\",\"A\",\"B\",\"A\", \"A\", \"C\", \"C\"])\n",
        "predicted_Y = np.array([\"A\",\"A\",\"A\",\"A\",\"A\", \"A\", \"A\", \"A\"])\n",
        "f1_score = macro_averaged_f1_score(actual_Y, predicted_Y)\n",
        "print(np.round(f1_score, 3))\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sum  0.6666666666666666\n",
            "0.222\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in long_scalars\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL-PvZB-pKpn"
      },
      "source": [
        "**Expected Output**:\n",
        "```\n",
        "0.611\n",
        "```"
      ]
    }
  ]
}